{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2781015,
          "sourceType": "datasetVersion",
          "datasetId": 1697740
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kalyanasundaram12/Predictive-Maintenances/blob/main/abnormalities_detection_and_predictive_maintenance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Abnormalities Detection and Predictive Maintenance for Industrial Equipment\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA and Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Abhijeet Panda\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Industrial machines generate large amounts of sensor data, such as temperature, speed, torque, and tool wear.  \n",
        "Detecting **failures** in this data is crucial to prevent unexpected breakdowns and improve operational efficiency.  \n",
        "\n",
        "This project aims to build a **machine learning model** that can:  \n",
        "1. **Identify failures** in industrial equipment based on sensor readings.  \n",
        "2. **Classify failure types** to help in troubleshooting.  \n",
        "3. **Visualize results** in a user-friendly dashboard for real-time monitoring.  \n",
        "\n",
        "\n",
        "## Dataset Overview  \n",
        "\n",
        "The dataset consists of **10,000 records** with the following features:  \n",
        "\n",
        "- **UID**: Unique identifier ranging from **1 to 10,000**.  \n",
        "- **Product ID**: Consists of a letter **L, M, or H**, representing product quality:  \n",
        "  - **L (50%)** – Low quality  \n",
        "  - **M (30%)** – Medium quality  \n",
        "  - **H (20%)** – High quality  \n",
        "  - Followed by a variant-specific serial number.  \n",
        "- **Air Temperature [K]**: Generated using a **random walk process**, normalized with a **standard deviation of 2 K** around **300 K**.  \n",
        "- **Process Temperature [K]**: Calculated as **Air Temperature + 10 K**, with a **standard deviation of 1 K**.  \n",
        "- **Rotational Speed [rpm]**: Derived from a **power of 2860 W**, overlaid with **normally distributed noise**.  \n",
        "- **Torque [Nm]**: Normally distributed around **40 Nm**, with a **standard deviation (σ) of 10 Nm** (no negative values).  \n",
        "- **Tool Wear [min]**:  \n",
        "  - **H (High Quality)** → +5 minutes  \n",
        "  - **M (Medium Quality)** → +3 minutes  \n",
        "  - **L (Low Quality)** → +2 minutes  \n",
        "- **Machine Failure (Target Variable)**:  \n",
        "  - Indicates whether the machine **has failed** at a given data point.  \n",
        "  - Failure can occur due to different **failure types**.  \n",
        "\n",
        "This dataset helps in detecting **machine failures** by analyzing sensor readings.   \n",
        "\n",
        "## Goal  \n",
        "- Use **machine learning** to detect machine failures.  \n",
        "- Develop a **dashboard** to visualize failure trends and provide alerts.  \n",
        "\n",
        "## Tools & Technologies  \n",
        "- **Python, Pandas, NumPy** for data processing  \n",
        "- **Scikit-learn** for machine learning models  \n",
        "- **Matplotlib, Seaborn** for data visualization  \n",
        "- **Flask** for building a simple user interface  \n",
        "- **Google Colab** for implementation  \n",
        "\n",
        "This project will help in **minimizing downtime**, **reducing maintenance costs**, and **improving machine reliability**.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objective**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Develop a machine learning model to detect abnormalities in sensor data from equipment.\n",
        "- Predict when maintenance is required to prevent equipment failure."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9QKLnqhY4eyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know the Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning and Pre-processing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "!pip install --quiet lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T13:48:36.487887Z",
          "iopub.execute_input": "2025-03-07T13:48:36.488249Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "3D PCA ANALYSIS"
      ],
      "metadata": {
        "id": "QxSYo-5U4UqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maintenance = pd.read_csv('/content/drive/MyDrive/predictive_maintenance.csv')\n",
        "#maintenance = maintenance[maintenance['Target'] != 0]\n",
        "maintenance = maintenance.drop(columns = ['UDI', 'Product ID', 'Target'])\n",
        "maintenance = maintenance.reset_index(drop = True)\n",
        "maintenance"
      ],
      "metadata": {
        "trusted": true,
        "id": "C-NU16Np4UqI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "label_mappings = {}\n",
        "\n",
        "for column in maintenance.select_dtypes('object'):\n",
        "    maintenance[column] = encoder.fit_transform(maintenance[column])\n",
        "    label_mappings[column] = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "\n",
        "for column, mapping in label_mappings.items():\n",
        "    print(f\"Column: {column}\")\n",
        "    for label, encoding in mapping.items():\n",
        "        print(f\"{encoding} -> {label}\")\n",
        "    print()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2TrXnhPo4UqI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 3)\n",
        "pca_maintenance = pca.fit_transform(maintenance.drop(columns = ['Failure Type']))\n",
        "pca_maintenance = pd.DataFrame(data = pca_maintenance, columns = ['PCA Component 1', 'PCA Component 2', 'PCA Component 3'])\n",
        "pca_maintenance['Failure Type'] = maintenance['Failure Type'].map({value: key for key, value in label_mappings['Failure Type'].items()})\n",
        "pca_maintenance"
      ],
      "metadata": {
        "trusted": true,
        "id": "q2fhwwc74UqI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pio.renderers.default = 'iframe'\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    pca_maintenance,\n",
        "    x = 'PCA Component 1',\n",
        "    y = 'PCA Component 2',\n",
        "    z = 'PCA Component 3',\n",
        "    color = 'Failure Type',\n",
        "    title = '3D PCA Projection Colored by Machine Failure Type',\n",
        "    labels = {\n",
        "        'PCA Component 1' : 'PCA Component 1',\n",
        "        'PCA Component 2' : 'PCA Component 2',\n",
        "        'PCA Component 3' : 'PCA Component 3',\n",
        "        'Failure Type' : 'Failure Type'\n",
        "    }\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "C_8Xkdhg4UqI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import kagglehub\n",
        "\n",
        "# # Download latest version\n",
        "# path = kagglehub.dataset_download(\"shivamb/machine-predictive-maintenance-classification\")\n",
        "\n",
        "# print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "trusted": true,
        "id": "45Npya2X4UqJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# print(os.listdir(\"/kaggle/input/machine-predictive-maintenance-classification\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "905i-Q4v4UqJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/predictive_maintenance.csv')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "aPdPUTfw4UqJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import kagglehub\n",
        "# path = kagglehub.dataset_download(\"shivamb/machine-predictive-maintenance-classification\")\n",
        "# print(\"Dataset downloaded to:\", path)\n",
        "# print(\"Contents:\", os.listdir(path))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "8inZhROz4UqJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "sum(data.duplicated())"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Check for missing values in each column\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_values)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset Describe"
      ],
      "metadata": {
        "id": "LfXLLAVYoTTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "mS6HXbBPoaoW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "unique_values = {col: data[col].nunique() for col in data.columns}\n",
        "\n",
        "# Convert to a DataFrame for better display\n",
        "unique_values_df = pd.DataFrame(list(unique_values.items()), columns=['Column', 'Unique Values'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(unique_values_df)\n",
        "\n",
        "# Count unique values in each column\n",
        "unique_counts = data.nunique()\n",
        "\n",
        "# Display unique values for columns with less than 10 unique values\n",
        "for col in data.columns:\n",
        "    if unique_counts[col] < 10:\n",
        "        print(f\"Column: {col}\")\n",
        "        print(\"Unique Values:\", data[col].unique())\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding the Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Summary\n",
        "\n",
        "#### 1. General Information\n",
        "- The dataset contains **10,000 rows** and **10 columns**.\n",
        "- There are **no missing values** or **null values** in any column.\n",
        "- There are **no duplicate records** in the dataset.\n",
        "\n",
        "#### 2. Unique Values\n",
        "- **UID** and **Product ID** have **10,000 unique values**, meaning each row has a unique identifier.\n",
        "- **Type** has **3 unique values**: `['M', 'L', 'H']`, representing different product quality levels.\n",
        "- **Target (Failure or Not)** has **2 unique values**: `[0, 1]`, where `0` means no failure and `1` means failure.\n",
        "- **Failure Type** has **6 unique values**:  \n",
        "  - `'No Failure'`  \n",
        "  - `'Power Failure'`  \n",
        "  - `'Tool Wear Failure'`  \n",
        "  - `'Overstrain Failure'`  \n",
        "  - `'Random Failures'`  \n",
        "  - `'Heat Dissipation Failure'`  \n",
        "\n",
        "#### 3. Statistical Insights\n",
        "- **Air Temperature [K]**: Ranges from **295.3 K to 304.5 K** with a mean of **300 K**.  \n",
        "- **Process Temperature [K]**: Ranges from **305.7 K to 313.8 K** with a mean of **310 K**.  \n",
        "- **Rotational Speed [rpm]**: Varies between **1168 and 2886 rpm**, with a mean of **1538 rpm**.  \n",
        "- **Torque [Nm]**: Ranges from **3.8 to 76.6 Nm**, with a mean of **39.98 Nm**.  \n",
        "- **Tool Wear [min]**: Varies between **0 and 253 minutes**, with a mean of **107.95 minutes**.  \n",
        "\n",
        "#### 4. Key Observations about Dataset\n",
        "- The dataset is **clean** with **no missing or duplicate values**.\n",
        "- Most features are **numerical**, except for **Type** and **Failure Type**, which are **categorical**.\n",
        "- **Failures occur in only a small portion of the data** (`Target` mean is **0.0339**, meaning ~3.4% of cases have failures).\n",
        "- **Different failure types** exist, making it important to classify failures properly.\n",
        "\n",
        "This dataset is well-structured for **machine failure detection** and will be used to train a model for **abnormality detection**."
      ],
      "metadata": {
        "id": "eFIJVDV7shSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shaving the dataset and creating a copy for further  studies\n",
        "df = data.copy()"
      ],
      "metadata": {
        "id": "B0h3msFz0Ilj",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling, Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables and takking Nacessary steps***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop ID columns\n",
        "df.drop(columns=['UDI','Product ID'], inplace=True)"
      ],
      "metadata": {
        "id": "ma0fiIq93_JP",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set numeric columns dtype to float\n",
        "df['Tool wear [min]'] = df['Tool wear [min]'].astype('float64')\n",
        "df['Rotational speed [rpm]'] = df['Rotational speed [rpm]'].astype('float64')\n",
        "# Rename features\n",
        "df.rename(mapper={'Air temperature [K]': 'Air temperature',\n",
        "                    'Process temperature [K]': 'Process temperature',\n",
        "                    'Rotational speed [rpm]': 'Rotational speed',\n",
        "                    'Torque [Nm]': 'Torque',\n",
        "                    'Tool wear [min]': 'Tool wear'}, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists of features and target names\n",
        "features = [col for col in df.columns\n",
        "            if df[col].dtype=='float64' or col =='Type']\n",
        "target = ['Target','Failure Type']\n",
        "# Portion of data where RNF=1\n",
        "idx_RNF = df.loc[df['Failure Type']=='Random Failures'].index\n",
        "df.loc[idx_RNF,target]"
      ],
      "metadata": {
        "id": "5YW6bbu34pS7",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "first_drop = df.loc[idx_RNF,target].shape[0]\n",
        "print('Number of observations where RNF=1 but Machine failure=0:',first_drop)\n",
        "# Drop corresponding observations and RNF column\n",
        "df.drop(index=idx_RNF, inplace=True)"
      ],
      "metadata": {
        "id": "XR8qjfqv8KGR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fortunately the machine failure RNF occurs in only 18 observations and it has a random nature therefore not predictable so we decide to remove these rows."
      ],
      "metadata": {
        "id": "G46aUMqt8Fn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Portion of data where Machine failure=1 but no failure cause is specified\n",
        "idx_ambiguous = df.loc[(df['Target']==1) &\n",
        "                       (df['Failure Type']=='No Failure')].index\n",
        "display(df.loc[idx_ambiguous,target])"
      ],
      "metadata": {
        "id": "GxREBuQe9cBN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Find indices where 'Target' is 1 but 'Failure Type' is 'No Failure'\n",
        "idx_ambiguous = df.loc[(df['Target'] == 1) & (df['Failure Type'] == 'No Failure')].index\n",
        "\n",
        "# Set 'Target' to 0 for these indices\n",
        "df.loc[idx_ambiguous, 'Target'] = 0"
      ],
      "metadata": {
        "id": "Tu-4XOUu92-i",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Outliers inspection"
      ],
      "metadata": {
        "id": "E0bupgu--o5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of numerical features\n",
        "num_features = [feature for feature in features if df[feature].dtype == 'float64']\n",
        "\n",
        "# Plot histograms\n",
        "plt.figure(figsize=(18, 7))\n",
        "plt.suptitle('Numeric Features - Histograms')\n",
        "\n",
        "for i, feature in enumerate(num_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.histplot(df[feature], bins=30, kde=True)\n",
        "    plt.title(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot boxplots\n",
        "plt.figure(figsize=(18, 7))\n",
        "plt.suptitle('Numeric Features - Boxplots')\n",
        "\n",
        "for i, feature in enumerate(num_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(x=df[feature])\n",
        "    plt.title(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7dGt_gKhAqEN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Outlier Analysis**\n",
        "\n",
        "- The **Rotational Speed** feature shows a **right-skewed distribution** with many extreme values on the higher side. The box plot also reveals a significant number of outliers. These outliers might indicate **sensor anomalies** or **unusual machine behavior** before failure.\n",
        "\n",
        "- The **Torque** feature has **outliers on both sides**, meaning there are extreme low and high values. These outliers could be crucial as they might represent **stress conditions** leading to equipment failure.\n",
        "\n",
        "#### **Decision on Outliers:**\n",
        "Instead of removing these outliers, I will **retain them** because they could be key indicators of faulty sensor data or **early signs of failure**. Removing them might result in the loss of valuable information necessary for **failure detection**."
      ],
      "metadata": {
        "id": "9MclEWPlByR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count target values\n",
        "target_counts = df['Target'].value_counts()\n",
        "\n",
        "# Create pie chart\n",
        "plt.pie(target_counts, labels=['No Failure', 'Failure'], autopct='%1.1f%%',\n",
        "        colors=['lightsalmon','seagreen' ], startangle=90)\n",
        "plt.title('Failure vs No Failure')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Filter data where failure occurred\n",
        "df_fail = df[df['Failure Type'] != 'No Failure']\n",
        "\n",
        "# Calculate failure type percentages\n",
        "failure_percentages = df_fail['Failure Type'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Plot pie chart\n",
        "plt.pie(failure_percentages, labels=failure_percentages.index, autopct='%.0f%%',\n",
        "        colors=sns.color_palette('pastel'), startangle=90)\n",
        "plt.title('Machine Failure Causes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KDE plot for numeric features\n",
        "fig, axs = plt.subplots(2, 3, figsize=(16, 7))\n",
        "fig.suptitle('Features Distribution')\n",
        "\n",
        "# Flatten the axes array for easier indexing\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, feature in enumerate(num_features):\n",
        "    sns.kdeplot(data=df, x=feature, hue='Target', fill=True, ax=axs[i], palette='tab10')\n",
        "\n",
        "# Hide unused subplots\n",
        "for j in range(i+1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CSceEadnGP0n",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Filter data where Target is 1 (machine failed)\n",
        "df_failed = df[df['Target'] == 1]\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(2, 3, figsize=(16, 7))\n",
        "fig.suptitle('Feature Distribution by Failure Type')\n",
        "\n",
        "axs = axs.flatten()  # Flatten for easy indexing\n",
        "\n",
        "for i, feature in enumerate(num_features):\n",
        "    sns.kdeplot(data=df_failed, x=feature, hue='Failure Type', fill=True, ax=axs[i], palette='tab10')\n",
        "\n",
        "# Remove empty subplots if there are fewer than 6 features\n",
        "for j in range(i + 1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Count plot for Type vs Target\n",
        "sns.countplot(data=df, x='Type', hue='Target', ax=axs[0])\n",
        "axs[0].set_title('Product Type vs Target (Failure or Not)')\n",
        "axs[0].legend(title='Target', labels=['No Failure', 'Failure'])\n",
        "\n",
        "# Count plot for Type vs Failure Type (only failed cases)\n",
        "df_failed = df[df['Target'] == 1]\n",
        "sns.countplot(data=df_failed, x='Type', hue='Failure Type', ax=axs[1], palette='pastel')\n",
        "axs[1].set_title('Product Type vs Failure Type')\n",
        "axs[1].legend(title='Failure Type')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cYrPNAzaIv2-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Figure\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Violin plot for Type vs Target\n",
        "sns.violinplot(data=df, x='Type', y='Target', ax=axs[0], palette='tab10')\n",
        "axs[0].set_title('Distribution of Target by Product Type')\n",
        "\n",
        "# Violin plot for Type vs Failure Type (only failed cases)\n",
        "df_failed = df[df['Failure Type'] != 'No Failure']\n",
        "sns.violinplot(data=df_failed, x='Type', y=df_failed['Failure Type'].astype('category').cat.codes, ax=axs[1], palette='tab10')\n",
        "axs[1].set_title('Distribution of Failure Type by Product Type')\n",
        "axs[1].set_yticks(range(len(df_failed['Failure Type'].unique())))\n",
        "axs[1].set_yticklabels(df_failed['Failure Type'].unique())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1_1-oiwfJJnM",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#copy the dataset for next preprocessing\n",
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "uo3_qAsJPMuj",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features scaling and Encoding\n"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In order to make data exploitable for the algorithms we will run, we apply two transformations:\n",
        "\n",
        "- First, we apply a label encoding to the categorical columns, since Type is an ordinal feature and Cause must be represented in one column. The mapping follows this scheme: Type: {L=0, M=1, H=2} Cause: {Working=0, PWF=1, OSF=2, HDF=3, TWF=4}"
      ],
      "metadata": {
        "id": "BL-z5SDWLh5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Encode categorical variables\n",
        "df1['Type'].replace({'L': 0, 'M': 1, 'H': 2}, inplace=True)\n",
        "df1['Failure Type'].replace({'No Failure': 0, 'Power Failure': 1, 'Overstrain Failure': 2, 'Heat Dissipation Failure': 3, 'Tool Wear Failure': 4}, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "8nleHN1HNVwt",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "A_xqQCyVUOMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(7,4))\n",
        "sns.heatmap(df1.corr(), mask=np.triu(df1.corr()), annot=True, cmap='vlag')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w_bdwT32OeqD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of the Correlation Heatmap**\n",
        "\n",
        "\n",
        "**A. Strong Positive Correlation (Red)**  \n",
        "- Process Temperature and Air Temperature (**0.88**)  \n",
        "  - As air temperature increases, process temperature also increases.  \n",
        "  - This makes sense because the process temperature depends on the surrounding air.  \n",
        "\n",
        "- Failure Type and Target (**0.91**)  \n",
        "  - This is expected because `Target` represents machine failure (1 = Failure, 0 = No Failure),  \n",
        "    and `Failure Type` categorizes those failures.  \n",
        "  - A machine can only have a failure type if it has failed (Target = 1).  \n",
        "\n",
        "**B. Strong Negative Correlation (Blue)**  \n",
        "- Torque and Rotational Speed (**-0.88**)  \n",
        "  - When the rotational speed increases, torque decreases, which aligns with physics principles.  \n",
        "  - High-speed machines usually require less torque to maintain motion.  \n",
        "\n",
        "**C. Medium Correlations (0.1 to 0.2)**  \n",
        "- Tool Wear has a weak positive correlation (**0.12**) with Target.  \n",
        "  - This means tool wear may contribute to failures, but it’s not the only factor.  \n",
        "  - Further analysis is needed to confirm its direct impact.  \n",
        "\n",
        "- Torque and Target (**0.19**)  \n",
        "  - A slight correlation suggests torque may play a role in machine failures,  \n",
        "    but other factors contribute as well.  \n",
        "\n",
        "**D. Low or No Correlation (Close to 0)**  \n",
        "- Type has almost no correlation with other features.  \n",
        "  - This suggests that machine type does not significantly impact failures or sensor readings.  \n",
        "  - We might want to check if this feature is truly important for modeling.  \n",
        "\n",
        "🔍 **Insights & Next Steps**   \n",
        "- Rotational speed and torque have a strong inverse relationship → Confirms expected physical behavior.  \n",
        "- Tool wear, torque, and temperature factors may contribute to failures → Further investigation is needed to confirm direct impact.  \n"
      ],
      "metadata": {
        "id": "bWzvxChGSHNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. Handaling Imbalance Data***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()"
      ],
      "metadata": {
        "id": "b4c-EkPSF8LG",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Over-Sampling with SMOTE (Synthetic Minority Oversampling Technique) to balance the dataset because the ‘No Failure’ class was significantly larger than the failure types. This imbalance could bias the model, making it predict ‘No Failure’ more often. SMOTE generated synthetic samples for the minority failure classes, helping the model learn patterns from all failure types and improving its ability to detect failures accurately.\n",
        "\n"
      ],
      "metadata": {
        "id": "YhFhm9V3lFVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "# Make a copy of df2 to avoid modifying original data\n",
        "df2_copy = df2.copy()\n",
        "\n",
        "# Convert 'Failure Type' to categorical codes\n",
        "df2_copy['Failure Type'] = df2_copy['Failure Type'].astype('category').cat.codes\n",
        "\n",
        "# Count 'No Failure' class\n",
        "n_working = (df2['Failure Type'] == 'No Failure').sum()\n",
        "\n",
        "# Calculate desired dataset length (80% of total)\n",
        "desired_length = round(n_working / 0.8)\n",
        "\n",
        "# Calculate samples per failure class\n",
        "spc = round((desired_length - n_working) / 4)\n",
        "\n",
        "# Define resampling strategy (now using numerical codes)\n",
        "balance_cause = {\n",
        "    df2_copy['Failure Type'].astype('category').cat.codes[df2['Failure Type'] == 'No Failure'].iloc[0]: n_working,\n",
        "    df2_copy['Failure Type'].astype('category').cat.codes[df2['Failure Type'] == 'Overstrain Failure'].iloc[0]: spc,\n",
        "    df2_copy['Failure Type'].astype('category').cat.codes[df2['Failure Type'] == 'Heat Dissipation Failure'].iloc[0]: spc,\n",
        "    df2_copy['Failure Type'].astype('category').cat.codes[df2['Failure Type'] == 'Power Failure'].iloc[0]: spc,\n",
        "    df2_copy['Failure Type'].astype('category').cat.codes[df2['Failure Type'] == 'Tool Wear Failure'].iloc[0]: spc\n",
        "}\n",
        "\n",
        "# Get categorical feature index\n",
        "cat_features = [df2.columns.get_loc('Type')]  # 'Type' is categorical\n",
        "\n",
        "# Apply SMOTENC\n",
        "sm = SMOTENC(categorical_features=cat_features, sampling_strategy=balance_cause, random_state=0)\n",
        "df_res, y_res = sm.fit_resample(df2_copy, df2_copy['Failure Type'])\n",
        "\n",
        "# Convert 'Failure Type' back to original labels\n",
        "df_res['Failure Type'] = df2['Failure Type'].astype('category').cat.categories[df_res['Failure Type']]\n",
        "\n",
        "# Show the resampled dataset\n",
        "df_res.head()"
      ],
      "metadata": {
        "id": "YaoNrWjHhfeP",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Portion of df_res where there is a failure and causes percentage\n",
        "df_res_fail = df_res[df_res['Failure Type'] != 'No Failure']\n",
        "fail_res_percentage = 100 * df_res_fail['Failure Type'].value_counts() / df_res_fail.shape[0]\n",
        "\n",
        "# Original failure percentage before SMOTE\n",
        "df_fail = df2[df2['Failure Type'] != 'No Failure']\n",
        "df_fail_percentage = 100 * df_fail['Failure Type'].value_counts() / df_fail.shape[0]\n",
        "\n",
        "# Percentage increase in dataset size\n",
        "print('Percentage increment of observations after oversampling:',\n",
        "      round((df_res.shape[0] - df2.shape[0]) * 100 / df2.shape[0], 2))\n",
        "print('SMOTE Resampled Failures percentage:',\n",
        "      round(df_res_fail.shape[0] * 100 / df_res.shape[0], 2))\n",
        "\n",
        "# Pie plot comparison\n",
        "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
        "fig.suptitle('Causes involved in Machine failures')\n",
        "\n",
        "# Original Data Pie Chart\n",
        "axs[0].pie(df_fail_percentage, labels=df_fail_percentage.index,\n",
        "           colors=sns.color_palette('tab10')[:5], autopct='%.0f%%')\n",
        "axs[0].set_title('Original')\n",
        "\n",
        "# SMOTE Resampled Data Pie Chart\n",
        "axs[1].pie(fail_res_percentage, labels=fail_res_percentage.index,\n",
        "           colors=sns.color_palette('tab10')[:5], autopct='%.0f%%')\n",
        "axs[1].set_title('After Resampling')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nl2H8yzUcGK1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# KDE plot of numeric features after resampling\n",
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(19, 7))\n",
        "fig.suptitle('Features Distribution (After Resampling)')\n",
        "\n",
        "# Custom color palette for Type categories\n",
        "custom_palette = {'L': 'tab:blue', 'M': 'tab:orange', 'H': 'tab:green'}\n",
        "\n",
        "# Loop through numeric features\n",
        "for j, feature in enumerate(num_features):\n",
        "    sns.kdeplot(ax=axs[j // 3, j % 3], data=df_res, x=feature,\n",
        "                hue=df_res['Type'], fill=True, palette=custom_palette)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z_RhBEzCdcR2",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# KDE plot of numeric features (Original) - Hue: Target\n",
        "fig, axs = plt.subplots(2, 3, figsize=(18, 7))\n",
        "fig.suptitle('Original Features Distribution')\n",
        "\n",
        "axs = axs.flatten()\n",
        "for i, feature in enumerate(num_features):\n",
        "    sns.kdeplot(data=df, x=feature, hue='Target', fill=True, ax=axs[i], palette='tab10')\n",
        "\n",
        "# Remove empty subplots if features < 6\n",
        "for j in range(i + 1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# KDE plot of numeric features (After Resampling) - Hue: Target\n",
        "fig, axs = plt.subplots(2, 3, figsize=(18, 7))\n",
        "fig.suptitle('Features Distribution After Oversampling')\n",
        "\n",
        "axs = axs.flatten()\n",
        "for i, feature in enumerate(num_features):\n",
        "    sns.kdeplot(data=df_res, x=feature, hue='Target', fill=True, ax=axs[i], palette='tab10')\n",
        "\n",
        "for j in range(i + 1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# KDE plot of numeric features (After Resampling) - Hue: Failure Type\n",
        "fig, axs = plt.subplots(2, 3, figsize=(18, 7))\n",
        "fig.suptitle('Features Distribution After Oversampling - Diving Deeper')\n",
        "\n",
        "axs = axs.flatten()\n",
        "for i, feature in enumerate(num_features):\n",
        "    sns.kdeplot(data=df_res, x=feature, hue='Failure Type', fill=True, ax=axs[i], palette='tab10')\n",
        "\n",
        "for j in range(i + 1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PguP-2KSeAl8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# KDE plot of numeric features (Original)\n",
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18, 7))\n",
        "fig.suptitle('Original Features Distribution')\n",
        "\n",
        "for j, feature in enumerate(num_features):\n",
        "    sns.kdeplot(ax=axs[j // 3, j % 3], data=df, x=feature,\n",
        "                hue=df['Target'], fill=True, palette='tab10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# KDE plot of numeric features (After Resampling)\n",
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18, 7))\n",
        "fig.suptitle('Features Distribution After Oversampling')\n",
        "\n",
        "for j, feature in enumerate(num_features):\n",
        "    sns.kdeplot(ax=axs[j // 3, j % 3], data=df_res, x=feature,\n",
        "                hue=df_res['Target'], fill=True, palette='tab10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# KDE plot of numeric features (After Resampling) - Diving Deeper\n",
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18, 7))\n",
        "fig.suptitle('Features Distribution After Oversampling - Diving Deeper')\n",
        "\n",
        "for j, feature in enumerate(num_features):\n",
        "    sns.kdeplot(ax=axs[j // 3, j % 3], data=df_res, x=feature,\n",
        "                hue=df_res['Failure Type'], fill=True, palette='tab10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XaWo47xJiZfv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml1 = df_res.copy()"
      ],
      "metadata": {
        "id": "0Vk25PcJn1zA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables\n",
        "df_ml1['Type'].replace({'L': 0, 'M': 1, 'H': 2}, inplace=True)\n",
        "df_ml1['Failure Type'].replace({'No Failure': 0, 'Power Failure': 1, 'Overstrain Failure': 2, 'Heat Dissipation Failure': 3, 'Tool Wear Failure': 4}, inplace=True)"
      ],
      "metadata": {
        "id": "akXjq7GaoS0F",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify numeric features with dtype float64\n",
        "num_features = [feature for feature in df_ml1.columns if df_ml1[feature].dtype == 'float64']\n",
        "\n",
        "# Scale numeric features\n",
        "df_ml1[num_features] = StandardScaler().fit_transform(df_ml1[num_features])"
      ],
      "metadata": {
        "id": "DiSeZMEToz2g",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML Models - 1 | Target Failure or Not Failure"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Features (X) and Target (y)"
      ],
      "metadata": {
        "id": "TIM2aOKWJhWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_ml1[['Process temperature', 'Rotational speed', 'Tool wear']]\n",
        "y = df_ml1['Target']"
      ],
      "metadata": {
        "id": "7ebyywQieS1U",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train_test_split"
      ],
      "metadata": {
        "id": "UnaYwytBKFX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "1NNDdldXJpEf",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    results = {\n",
        "        'Model': model_name,\n",
        "        'Train Accuracy': accuracy_score(y_train, y_train_pred),\n",
        "        'Test Accuracy': accuracy_score(y_test, y_test_pred),\n",
        "        'F1 Score': f1_score(y_test, y_test_pred),\n",
        "        'Precision': precision_score(y_test, y_test_pred),\n",
        "        'Recall': recall_score(y_test, y_test_pred)\n",
        "    }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "WdWSBTVGsHK0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train Logistic Regression with GridSearchCV**"
      ],
      "metadata": {
        "id": "D3kKm9trJ1Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_lr = {'C': [0.1, 1, 10], 'solver': ['liblinear']}\n",
        "grid_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='accuracy')\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "best_lr = grid_lr.best_estimator_\n",
        "lr_results = evaluate_model(best_lr, 'Logistic Regression', X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "id": "ihJ5Ipu5sLpb",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train KNN with GridSearchCV**"
      ],
      "metadata": {
        "id": "VtAijdvpKSfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_knn = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='accuracy')\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "best_knn = grid_knn.best_estimator_\n",
        "knn_results = evaluate_model(best_knn, 'KNN', X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "f1w0CR_xJsbT",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train SVC with GridSearchCV**"
      ],
      "metadata": {
        "id": "Ydq6o8wdKuXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='accuracy')\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "svm_results = evaluate_model(best_svm, 'SVM', X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "r_M2ajJIJsYO",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train Naïve Bayes**"
      ],
      "metadata": {
        "id": "ktWSJxkfLQVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb = GaussianNB()\n",
        "nb_results = evaluate_model(nb, 'Naïve Bayes', X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "N5cmVDdALM-3",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **XGBClassifier**"
      ],
      "metadata": {
        "id": "kOdDBiS3s-ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_xgb = {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [50, 100, 200]}\n",
        "grid_xgb = GridSearchCV(XGBClassifier(eval_metric='mlogloss'), param_grid_xgb, cv=5, scoring='accuracy')\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "xgb_results = evaluate_model(best_xgb, 'XGBoost', X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "id": "EBXiovdYs92z",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM"
      ],
      "metadata": {
        "id": "8Pg_3Fxb7O5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MGQgN1NW7tls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier # Import the LGBMClassifier class\n",
        "param_grid_lgbm = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "grid_lgbm = GridSearchCV(LGBMClassifier(random_state=42), param_grid_lgbm, cv=5, scoring='accuracy')\n",
        "grid_lgbm.fit(X_train, y_train)\n",
        "best_lgbm = grid_lgbm.best_estimator_\n",
        "lgbm_results = evaluate_model(best_lgbm, 'LightGBM', X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "8iJeidJwyj7t",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame([lr_results, knn_results, svm_results, nb_results, xgb_results, lgbm_results])\n",
        "\n",
        "# Display results\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "uOqvPdwXviRd",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all results in a DataFrame\n",
        "results_df = pd.DataFrame([lr_results, knn_results, svm_results, nb_results, xgb_results,lgbm_results])\n",
        "\n",
        "# Define metrics to visualize\n",
        "metrics = ['Train Accuracy', 'Test Accuracy', 'F1 Score', 'Precision', 'Recall']\n",
        "\n",
        "# Set figure size\n",
        "fig, axes = plt.subplots(1, len(metrics), figsize=(22, 6), sharey=True)\n",
        "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Create bar plots for each metric\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Use 'hue' to fix the seaborn warning\n",
        "    bars = sns.barplot(x='Model', y=metric, hue='Model', data=results_df, ax=ax)\n",
        "\n",
        "    # Set proper x-ticks to avoid warning\n",
        "    ax.set_xticks(range(len(results_df['Model'])))\n",
        "    ax.set_xticklabels(results_df['Model'], rotation=90, ha=\"center\")\n",
        "\n",
        "    # Annotate bars dynamically\n",
        "    for bar in bars.patches:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 6 if height < 0.9 else -20),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', fontsize=10, fontweight='bold',\n",
        "                    color='black' if height < 0.9 else 'white')  # Change text color dynamically\n",
        "\n",
        "    ax.set_title(metric, fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('')\n",
        "    ax.set_ylim(0, 1.1)  # Slightly increase y-limit to avoid text cutoff\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3y9SC-XDvabZ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the best XGBoost model\n",
        "joblib.dump(best_xgb, 'best_lgbm_model.pkl')\n",
        "print(\"Best LGBM model saved as 'best_xgb_model.pkl'\")"
      ],
      "metadata": {
        "id": "Gz-eKqwQz3A-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML Model - 2 | Failure Type"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select rows where 'Target' is 1\n",
        "df_failure = df_ml1[df_ml1['Target'] == 1].copy()\n",
        "\n",
        "# Define features and target\n",
        "X_failure = df_failure[['Process temperature', 'Rotational speed', 'Tool wear']]\n",
        "y_failure = df_failure['Failure Type']"
      ],
      "metadata": {
        "id": "oHL73M7c8rfy",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train_test_split"
      ],
      "metadata": {
        "id": "z6pVtGcwJ7_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
        "    X_failure, y_failure, test_size=0.3, random_state=42, stratify=y_failure)"
      ],
      "metadata": {
        "id": "dnu1_ukY9D5J",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Train Accuracy': accuracy_score(y_train, y_train_pred),\n",
        "        'Test Accuracy': accuracy_score(y_test, y_test_pred),\n",
        "        'F1 Score': f1_score(y_test, y_test_pred, average='weighted'),\n",
        "        'Precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
        "        'Recall': recall_score(y_test, y_test_pred, average='weighted')\n",
        "    }"
      ],
      "metadata": {
        "id": "OYzteNTK9zoW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LogisticRegression"
      ],
      "metadata": {
        "id": "tAe6lSbRJ3Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_lr = {'C': [0.1, 1, 10], 'solver': ['lbfgs']}\n",
        "grid_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='accuracy')\n",
        "grid_lr.fit(X_train_f, y_train_f)\n",
        "\n",
        "best_lr = grid_lr.best_estimator_\n",
        "lr_results = evaluate_model(best_lr, 'Logistic Regression', X_train_f, X_test_f, y_train_f, y_test_f)\n"
      ],
      "metadata": {
        "id": "i70b-HkS9D0a",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### KNN"
      ],
      "metadata": {
        "id": "2X_84zHCJv8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "param_grid_knn = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='accuracy')\n",
        "grid_knn.fit(X_train_f, y_train_f)\n",
        "\n",
        "best_knn = grid_knn.best_estimator_\n",
        "knn_results = evaluate_model(best_knn, 'KNN', X_train_f, X_test_f, y_train_f, y_test_f)"
      ],
      "metadata": {
        "id": "GGLZFi0Q9Dxm",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVC"
      ],
      "metadata": {
        "id": "mHxa2kKnJtXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='accuracy')\n",
        "grid_svm.fit(X_train_f, y_train_f)\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "svm_results = evaluate_model(best_svm, 'SVM', X_train_f, X_test_f, y_train_f, y_test_f)"
      ],
      "metadata": {
        "id": "DY4LKZga97Rt",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naïve Bayes"
      ],
      "metadata": {
        "id": "IwvTUVSQJpNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_f, y_train_f)\n",
        "\n",
        "nb_results = evaluate_model(nb, 'Naïve Bayes', X_train_f, X_test_f, y_train_f, y_test_f)"
      ],
      "metadata": {
        "id": "j5W8iEr_97PA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### xgboost"
      ],
      "metadata": {
        "id": "47EVYgyZKOLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200]\n",
        "}\n",
        "\n",
        "# Adjust class labels to start from 0 if necessary\n",
        "y_train_f_adj = y_train_f - y_train_f.min()\n",
        "y_test_f_adj = y_test_f - y_test_f.min()\n",
        "\n",
        "# Define XGBClassifier without `use_label_encoder`\n",
        "grid_xgb = GridSearchCV(\n",
        "    XGBClassifier(objective='multi:softmax', num_class=len(set(y_train_f_adj)), eval_metric='mlogloss'),\n",
        "    param_grid_xgb, cv=5, scoring='accuracy'\n",
        ")\n",
        "\n",
        "grid_xgb.fit(X_train_f, y_train_f_adj)\n",
        "\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "xgb_results = evaluate_model(best_xgb, 'XGBoost', X_train_f, X_test_f, y_train_f_adj, y_test_f_adj)\n"
      ],
      "metadata": {
        "id": "kqhHhwXR_X-T",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LightGBM**"
      ],
      "metadata": {
        "id": "BeygJOVT8ccx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier  # Add LightGBM import\n",
        "# Train LightGBM with GridSearchCV\n",
        "param_grid_lgbm = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "grid_lgbm = GridSearchCV(\n",
        "    LGBMClassifier(objective='multiclass', num_class=len(set(y_train_f_adj)), random_state=42),\n",
        "    param_grid_lgbm, cv=5, scoring='accuracy'\n",
        ")\n",
        "grid_lgbm.fit(X_train_f, y_train_f_adj)\n",
        "best_lgbm = grid_lgbm.best_estimator_\n",
        "lgbm_results = evaluate_model(best_lgbm, 'LightGBM', X_train_f, X_test_f, y_train_f_adj, y_test_f_adj)"
      ],
      "metadata": {
        "id": "QW8NFi1T8esI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Collect all results in a DataFrame\n",
        "results_df = pd.DataFrame([\n",
        "    lr_results,\n",
        "    knn_results,\n",
        "    svm_results,\n",
        "    nb_results,\n",
        "    xgb_results,\n",
        "    lgbm_results\n",
        "])\n",
        "\n",
        "# Display results\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "aXrN-qxwClHs",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect results\n",
        "results_df_f = pd.DataFrame([lr_results, knn_results, svm_results, nb_results, xgb_results,lgbm_results])\n",
        "\n",
        "# Define metrics to visualize\n",
        "metrics = ['Train Accuracy', 'Test Accuracy', 'F1 Score', 'Precision', 'Recall']\n",
        "\n",
        "# Set figure size\n",
        "fig, axes = plt.subplots(1, len(metrics), figsize=(22, 6), sharey=True)\n",
        "fig.suptitle('Failure Type Prediction - Model Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Create bar plots for each metric\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax = axes[i]\n",
        "    bars = sns.barplot(x='Model', y=metric, hue='Model', data=results_df_f, ax=ax, palette='viridis')\n",
        "\n",
        "    ax.set_xticks(range(len(results_df_f['Model'])))\n",
        "    ax.set_xticklabels(results_df_f['Model'], rotation=90, ha=\"center\")\n",
        "\n",
        "    for bar in bars.patches:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 6 if height < 0.9 else -20),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', fontsize=10, fontweight='bold',\n",
        "                    color='black' if height < 0.9 else 'white')\n",
        "\n",
        "    ax.set_title(metric, fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('')\n",
        "    ax.set_ylim(0, 1.1)  # Slightly increase y-limit to avoid text cutoff\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rbOXLEcmCDfE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best XGBoost model\n",
        "joblib.dump(best_xgb, 'best_lgbm_model2.pkl')\n",
        "print(\"Model saved as best_lgbm_model.pkl2.pkl\")"
      ],
      "metadata": {
        "id": "UB3xF2jdFCnY",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CBA**"
      ],
      "metadata": {
        "id": "q4RStQTn829r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "# Load the best model (e.g., LightGBM)\n",
        "model = joblib.load('best_lgbm_model.pkl')  # Use the saved LightGBM model for Failure/No Failure\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Cost assumptions\n",
        "cost_downtime_hour = 500  # $ per hour\n",
        "cost_repair = 2000  # $ per failure (reactive)\n",
        "cost_preventive = 500  # $ per preventive maintenance\n",
        "downtime_reactive = 4  # hours per failure\n",
        "downtime_preventive = 1  # hours per preventive action\n",
        "\n",
        "# Calculate costs for Reactive Maintenance (no model)\n",
        "reactive_costs = []\n",
        "for actual in y_test:\n",
        "    if actual == 1:  # Failure occurs\n",
        "        cost = cost_repair + (downtime_reactive * cost_downtime_hour)\n",
        "    else:  # No failure\n",
        "        cost = 0\n",
        "    reactive_costs.append(cost)\n",
        "total_reactive_cost = sum(reactive_costs)\n",
        "\n",
        "# Calculate costs for Predictive Maintenance (with model)\n",
        "predictive_costs = []\n",
        "false_negatives = 0\n",
        "false_positives = 0\n",
        "true_positives = 0\n",
        "\n",
        "for actual, pred in zip(y_test, y_pred):\n",
        "    if actual == 1 and pred == 1:  # True Positive (failure predicted correctly)\n",
        "        cost = cost_preventive + (downtime_preventive * cost_downtime_hour)\n",
        "        true_positives += 1\n",
        "    elif actual == 1 and pred == 0:  # False Negative (failure missed)\n",
        "        cost = cost_repair + (downtime_reactive * cost_downtime_hour)\n",
        "        false_negatives += 1\n",
        "    elif actual == 0 and pred == 1:  # False Positive (unnecessary maintenance)\n",
        "        cost = cost_preventive + (downtime_preventive * cost_downtime_hour)\n",
        "        false_positives += 1\n",
        "    else:  # True Negative (no failure, no action)\n",
        "        cost = 0\n",
        "    predictive_costs.append(cost)\n",
        "total_predictive_cost = sum(predictive_costs)\n",
        "\n",
        "# Savings\n",
        "savings = total_reactive_cost - total_predictive_cost\n",
        "\n",
        "# Print results\n",
        "print(f\"Total Reactive Maintenance Cost: ${total_reactive_cost:,.2f}\")\n",
        "print(f\"Total Predictive Maintenance Cost: ${total_predictive_cost:,.2f}\")\n",
        "print(f\"Total Savings with Predictive Maintenance: ${savings:,.2f}\")\n",
        "print(f\"False Negatives (Missed Failures): {false_negatives}\")\n",
        "print(f\"False Positives (Unnecessary Maintenance): {false_positives}\")\n",
        "print(f\"True Positives (Correctly Predicted Failures): {true_positives}\")\n",
        "\n",
        "# Enhanced Visualization 1: Stacked Bar Plot for Cost Comparison\n",
        "plt.figure(figsize=(12, 7))\n",
        "reactive_downtime_cost = sum([downtime_reactive * cost_downtime_hour if actual == 1 else 0 for actual in y_test])\n",
        "reactive_repair_cost = sum([cost_repair if actual == 1 else 0 for actual in y_test])\n",
        "predictive_downtime_cost = (true_positives + false_positives) * downtime_preventive * cost_downtime_hour + false_negatives * downtime_reactive * cost_downtime_hour\n",
        "predictive_action_cost = (true_positives + false_positives) * cost_preventive + false_negatives * cost_repair\n",
        "\n",
        "bar_width = 0.5\n",
        "plt.bar(['Reactive Maintenance'], reactive_repair_cost, bar_width, label='Repair Cost', color='salmon')\n",
        "plt.bar(['Reactive Maintenance'], reactive_downtime_cost, bar_width, bottom=reactive_repair_cost, label='Downtime Cost', color='lightcoral')\n",
        "plt.bar(['Predictive Maintenance'], predictive_action_cost, bar_width, label='Maintenance/Repair Cost', color='skyblue')\n",
        "plt.bar(['Predictive Maintenance'], predictive_downtime_cost, bar_width, bottom=predictive_action_cost, label='Downtime Cost', color='lightblue')\n",
        "\n",
        "plt.title('Cost Comparison: Reactive vs Predictive Maintenance', fontsize=16, fontweight='bold', pad=15)\n",
        "plt.ylabel('Total Cost ($)', fontsize=14)\n",
        "plt.legend(title='Cost Components', fontsize=12, title_fontsize=14)\n",
        "for i, total in enumerate([total_reactive_cost, total_predictive_cost]):\n",
        "    plt.text(i, total + 5000, f\"${total:,.2f}\", ha='center', fontsize=12, fontweight='bold', color='black')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Enhanced Visualization 2: Pie Chart for Predictive Maintenance Cost Breakdown\n",
        "plt.figure(figsize=(10, 10))\n",
        "breakdown_labels = ['True Positives', 'False Positives', 'False Negatives']\n",
        "breakdown_costs = [\n",
        "    true_positives * (cost_preventive + downtime_preventive * cost_downtime_hour),\n",
        "    false_positives * (cost_preventive + downtime_preventive * cost_downtime_hour),\n",
        "    false_negatives * (cost_repair + downtime_reactive * cost_downtime_hour)\n",
        "]\n",
        "colors = sns.color_palette('pastel', len(breakdown_labels))\n",
        "explode = (0.05, 0.05, 0.05)  # Slightly explode all slices for emphasis\n",
        "\n",
        "plt.pie(breakdown_costs, labels=breakdown_labels, autopct=lambda pct: f\"${int(pct/100*sum(breakdown_costs)):,.0f}\\n({pct:.1f}%)\",\n",
        "        startangle=90, colors=colors, explode=explode, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
        "plt.title('Predictive Maintenance Cost Breakdown', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures pie is circular\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Enhanced Visualization 3: Bar Plot with Error Bars for Savings\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Simulate uncertainty with a standard error (e.g., 10% of savings as an example)\n",
        "savings_error = savings * 0.1  # 10% variability as a placeholder\n",
        "sns.barplot(x=['Savings'], y=[savings], hue=['Savings'], palette='Greens', errorbar=None)\n",
        "plt.errorbar(x=0, y=savings, yerr=savings_error, fmt='none', c='black', capsize=5, capthick=2, linewidth=2)\n",
        "\n",
        "plt.title('Savings with Predictive Maintenance', fontsize=16, fontweight='bold', pad=15)\n",
        "plt.ylabel('Savings ($)', fontsize=14)\n",
        "plt.text(0, savings + savings_error + 5000, f\"${savings:,.2f}\", ha='center', fontsize=12, fontweight='bold', color='black')\n",
        "plt.annotate('±10% Uncertainty', xy=(0, savings + savings_error), xytext=(0, savings + savings_error + 10000),\n",
        "             ha='center', fontsize=10, color='gray')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H_E2tZj_81m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Deployment**"
      ],
      "metadata": {
        "id": "YrdGWYmMILNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!ngrok authtoken 2tuU1MF7s5T7cAyFNWMyVRNEhFT_4FJByH9mu2e38GpQMwRZc"
      ],
      "metadata": {
        "id": "8t3b_AvAy4Sz",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import joblib\n",
        "# import pandas as pd\n",
        "# from flask import Flask, request, jsonify, render_template_string\n",
        "# from pyngrok import ngrok\n",
        "\n",
        "# # Load the models\n",
        "# model_target = joblib.load(\"best_xgb_model.pkl\")  # Model for predicting Failure/No Failure\n",
        "# model_failure_type = joblib.load(\"best_xgb_model2.pkl\")  # Model for predicting Failure Type\n",
        "\n",
        "# # Failure Type Mapping (as used during training)\n",
        "# failure_type_mapping = {\n",
        "#     0: \"No Failure\",\n",
        "#     1: \"Power Failure\",\n",
        "#     2: \"Overstrain Failure\",\n",
        "#     3: \"Heat Dissipation Failure\",\n",
        "#     4: \"Tool Wear Failure\"\n",
        "# }\n",
        "\n",
        "# # Initialize Flask App\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# # HTML Template for User Input\n",
        "# HTML_TEMPLATE = \"\"\"\n",
        "# <!DOCTYPE html>\n",
        "# <html>\n",
        "# <head>\n",
        "#     <title>Predictive Maintenance Model</title>\n",
        "# </head>\n",
        "# <body>\n",
        "#     <h2>Enter Machine Parameters</h2>\n",
        "#     <form action=\"/predict\" method=\"post\">\n",
        "#         <label for=\"machine_type\">Machine Type:</label>\n",
        "#         <select name=\"machine_type\">\n",
        "#             <option value=\"0\">L</option>\n",
        "#             <option value=\"1\">M</option>\n",
        "#             <option value=\"2\">H</option>\n",
        "#         </select><br><br>\n",
        "\n",
        "#         <label for=\"air_temp\">Air Temperature [K]:</label>\n",
        "#         <input type=\"number\" step=\"any\" name=\"air_temp\" required><br><br>\n",
        "\n",
        "#         <label for=\"process_temp\">Process Temperature [K]:</label>\n",
        "#         <input type=\"number\" step=\"any\" name=\"process_temp\" required><br><br>\n",
        "\n",
        "#         <label for=\"rot_speed\">Rotational Speed [rpm]:</label>\n",
        "#         <input type=\"number\" step=\"any\" name=\"rot_speed\" required><br><br>\n",
        "\n",
        "#         <label for=\"torque\">Torque [Nm]:</label>\n",
        "#         <input type=\"number\" step=\"any\" name=\"torque\" required><br><br>\n",
        "\n",
        "#         <label for=\"tool_wear\">Tool Wear [min]:</label>\n",
        "#         <input type=\"number\" step=\"any\" name=\"tool_wear\" required><br><br>\n",
        "\n",
        "#         <button type=\"submit\">Predict</button>\n",
        "#     </form>\n",
        "\n",
        "#     {% if prediction is not none %}\n",
        "#         <h3>Prediction: {{ prediction }}</h3>\n",
        "#         {% if failure_type is not none %}\n",
        "#             <h3>Failure Type: {{ failure_type }}</h3>\n",
        "#         {% endif %}\n",
        "#     {% endif %}\n",
        "# </body>\n",
        "# </html>\n",
        "# \"\"\"\n",
        "\n",
        "# @app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "# def home():\n",
        "#     return render_template_string(HTML_TEMPLATE)\n",
        "\n",
        "# @app.route(\"/predict\", methods=[\"POST\"])\n",
        "# def predict():\n",
        "#     try:\n",
        "#         if request.form:\n",
        "#             # Extract user input\n",
        "#             data = {\n",
        "#                 \"Type\": int(request.form[\"machine_type\"]),  # Convert to integer (0=L, 1=M, 2=H)\n",
        "#                 \"Air temperature\": float(request.form[\"air_temp\"]),\n",
        "#                 \"Process temperature\": float(request.form[\"process_temp\"]),\n",
        "#                 \"Rotational speed\": float(request.form[\"rot_speed\"]),\n",
        "#                 \"Torque\": float(request.form[\"torque\"]),\n",
        "#                 \"Tool wear\": float(request.form[\"tool_wear\"]),\n",
        "#             }\n",
        "#         else:\n",
        "#             data = request.get_json()\n",
        "\n",
        "#         # Convert to DataFrame\n",
        "#         df = pd.DataFrame([data])\n",
        "#         print(df[['Process temperature', 'Rotational speed', 'Tool wear']])\n",
        "\n",
        "#         # **Step 1: Predict Failure or No Failure**\n",
        "#         target_prediction = model_target.predict(df[['Process temperature', 'Rotational speed', 'Tool wear']])[0]\n",
        "#         prediction_text = \"Failure\" if target_prediction == 1 else \"No Failure\"\n",
        "\n",
        "#         failure_type_text = None  # Default to None\n",
        "\n",
        "#         if target_prediction == 1:\n",
        "#             # **Step 2: Predict Failure Type if Target is Failure**\n",
        "\n",
        "#             # Explicitly rename features to match those used in `best_xgb_model2.pkl`\n",
        "#             df_failure = df.rename(columns={\n",
        "#                 \"Process temperature [K]\": \"Process temperature\",\n",
        "#                 \"Rotational speed [rpm]\": \"Rotational speed\",\n",
        "#                 \"Tool wear [min]\": \"Tool wear\"\n",
        "#             })\n",
        "\n",
        "#             # Select only the required columns for failure type prediction\n",
        "#             df_failure = df_failure[[\"Process temperature\", \"Rotational speed\", \"Tool wear\"]]\n",
        "\n",
        "#             # Predict failure type\n",
        "#             failure_type_prediction = model_failure_type.predict(df_failure)[0]\n",
        "#             failure_type_text = failure_type_mapping.get(failure_type_prediction, \"Unknown Failure Type\")\n",
        "\n",
        "#         return render_template_string(HTML_TEMPLATE, prediction=prediction_text, failure_type=failure_type_text)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         return jsonify({\"error\": str(e)})\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     PORT = 5001  # Change port if needed\n",
        "\n",
        "#     # Start ngrok tunnel\n",
        "#     public_url = ngrok.connect(PORT).public_url\n",
        "#     print(f\"Public URL: {public_url}\")\n",
        "\n",
        "#     # Run Flask App\n",
        "#     app.run(port=PORT)\n"
      ],
      "metadata": {
        "id": "aPtxI2A0hxLB",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Industrial Equipment Predictive Maintenance Dataset\n",
        "\n",
        "This dataset contains sensor readings from industrial machines and their corresponding failure types. Each row represents a machine's operational parameters at a given time, along with its failure classification.\n",
        "\n",
        "| Type | Air Temperature [K] | Process Temperature [K] | Rotational Speed [rpm] | Torque [Nm] | Tool Wear [min] | Failure (1=Yes, 0=No) | Failure Type |\n",
        "|------|---------------------|-------------------------|------------------------|-------------|----------------|------------------------|--------------|\n",
        "| L    | 298.9               | 309.1                   | 2861                   | 4.6         | 143            | 1                      | Power Failure |\n",
        "| L    | 298.9               | 309.0                   | 1410                   | 65.7        | 191            | 1                      | Power Failure |\n",
        "| L    | 298.8               | 308.9                   | 1455                   | 41.3        | 208            | 1                      | Tool Wear Failure |\n",
        "| L    | 298.4               | 308.2                   | 1282                   | 60.7        | 216            | 1                      | Overstrain Failure |\n",
        "| L    | 298.3               | 308.1                   | 1412                   | 52.3        | 218            | 1                      | Overstrain Failure |\n",
        "| L    | 298.4               | 308.3                   | 1433                   | 62.3        | 20             | 1                      | Power Failure |\n",
        "| M    | 298.2               | 308.5                   | 2678                   | 10.7        | 86             | 1                      | Power Failure |\n",
        "| M    | 298.4               | 308.7                   | 1421                   | 60.7        | 119            | 1                      | Power Failure |\n",
        "| L    | 298.0               | 308.2                   | 1348                   | 58.8        | 202            | 1                      | Overstrain Failure |\n",
        "| L    | 298.0               | 308.3                   | 1362                   | 56.8        | 216            | 1                      | Overstrain Failure |\n",
        "| L    | 298.0               | 308.3                   | 1405                   | 56.2        | 218            | 1                      | Overstrain Failure |\n",
        "| M    | 298.1               | 308.2                   | 1420                   | 63.9        | 19             | 1                      | Power Failure |\n",
        "| L    | 297.7               | 308.5                   | 1373                   | 56.7        | 203            | 1                      | Overstrain Failure |\n",
        "| L    | 297.5               | 308.3                   | 2564                   | 12.8        | 127            | 1                      | Power Failure |\n",
        "| L    | 297.4               | 308.5                   | 1399                   | 61.5        | 61             | 1                      | Power Failure |\n",
        "| L    | 297.4               | 308.7                   | 2874                   | 4.2         | 118            | 1                      | Power Failure |\n",
        "| L    | 297.6               | 309.6                   | 1501                   | 49.8        | 222            | 1                      | Overstrain Failure |\n",
        "| L    | 297.9               | 309.8                   | 1336                   | 71.6        | 31             | 1                      | Power Failure |\n",
        "| L    | 296.8               | 308.1                   | 1289                   | 62.0        | 199            | 1                      | Overstrain Failure |\n",
        "| L    | 296.4               | 307.4                   | 2833                   | 5.6         | 213            | 1                      | Power Failure |\n",
        "| M    | 295.8               | 306.3                   | 1235                   | 76.2        | 89             | 1                      | Power Failure |\n",
        "| L    | 295.7               | 306.2                   | 2270                   | 14.6        | 149            | 1                      | Power Failure |\n",
        "| L    | 295.6               | 306.1                   | 1372                   | 55.6        | 215            | 1                      | Overstrain Failure |\n",
        "| M    | 296.3               | 307.2                   | 1319                   | 68.3        | 24             | 1                      | Power Failure |\n",
        "| L    | 297.0               | 307.8                   | 1385                   | 56.4        | 202            | 1                      | Overstrain Failure |\n",
        "| H    | 296.9               | 307.8                   | 1549                   | 35.8        | 206            | 1                      | Tool Wear Failure |\n",
        "| L    | 296.9               | 307.5                   | 2721                   | 9.3         | 18             | 1                      | Power Failure |\n",
        "| H    | 296.6               | 307.7                   | 1386                   | 62.3        | 100            | 1                      | Power Failure |\n",
        "| M    | 296.7               | 307.8                   | 1258                   | 69.0        | 105            | 1                      | Power Failure |\n",
        "\n",
        "---\n",
        "\n",
        "> **Note:**  \n",
        "> - `Failure` column: **1** = Machine Failure, **0** = No Failure.  \n",
        "> - `Failure Type`: The reason for failure (e.g., **Power Failure, Overstrain Failure, Tool Wear Failure**).  \n",
        "> - The dataset captures operational parameters like **temperature, rotational speed, torque, and tool wear** to predict failures.  \n",
        "\n",
        "---\n",
        "\n",
        "## **How to Use This Data?**\n",
        "1. Train a **predictive maintenance model** to classify failure vs. no failure.\n",
        "2\n"
      ],
      "metadata": {
        "id": "5qmYzEubufQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load trained models\n",
        "model_target = joblib.load(\"best_xgb_model.pkl\")  # Model for Failure/No Failure\n",
        "model_failure_type = joblib.load(\"best_xgb_model2.pkl\")  # Model for Failure Type\n",
        "\n",
        "# Failure Type Mapping (as used during training)\n",
        "failure_type_mapping = {\n",
        "    0: \"No Failure\",\n",
        "    1: \"Power Failure\",\n",
        "    2: \"Overstrain Failure\",\n",
        "    3: \"Heat Dissipation Failure\",\n",
        "    4: \"Tool Wear Failure\"\n",
        "}\n",
        "\n",
        "# Reverse mapping (for comparison with actual values)\n",
        "failure_type_reverse_mapping = {v: k for k, v in failure_type_mapping.items()}\n",
        "\n",
        "# ✅ **Load Your Data**\n",
        "data = [\n",
        "    [\"L\", 298.9, 309.1, 2861, 4.6, 143, 1, \"Power Failure\"],\n",
        "    [\"L\", 298.9, 309.0, 1410, 65.7, 191, 1, \"Power Failure\"],\n",
        "    [\"L\", 298.8, 308.9, 1455, 41.3, 208, 1, \"Tool Wear Failure\"],\n",
        "    [\"L\", 298.4, 308.2, 1282, 60.7, 216, 1, \"Overstrain Failure\"],\n",
        "    [\"L\", 298.3, 308.1, 1412, 52.3, 218, 1, \"Overstrain Failure\"],\n",
        "    [\"L\", 298.4, 308.3, 1433, 62.3, 20, 1, \"Power Failure\"],\n",
        "    [\"M\", 298.2, 308.5, 2678, 10.7, 86, 1, \"Power Failure\"],\n",
        "    [\"M\", 298.4, 308.7, 1421, 60.7, 119, 1, \"Power Failure\"],\n",
        "    [\"L\", 298.0, 308.2, 1348, 58.8, 202, 1, \"Overstrain Failure\"],\n",
        "    [\"L\", 298.0, 308.3, 1362, 56.8, 216, 1, \"Overstrain Failure\"],\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "columns = [\"Type\", \"Air temperature\", \"Process temperature\", \"Rotational speed\", \"Torque\", \"Tool wear\", \"Actual Failure\", \"Actual Failure Type\"]\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "df"
      ],
      "metadata": {
        "id": "tgOYFB3OG6pz",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ **Preprocess Data for Model**\n",
        "# Encode Machine Type (L=0, M=1, H=2)\n",
        "df[\"Type\"] = df[\"Type\"].map({\"L\": 0, \"M\": 1, \"H\": 2})\n",
        "\n",
        "# **Step 1: Predict Failure or No Failure**\n",
        "df[\"Predicted Failure\"] = model_target.predict(df.drop(columns=[\"Type\", \"Actual Failure\", \"Actual Failure Type\", \"Air temperature\", \"Torque\"]))\n",
        "df"
      ],
      "metadata": {
        "id": "5mQZn6P7wQTS",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# **Step 2: Predict Failure Type if Failure is Detected**\n",
        "df[\"Predicted Failure Type\"] = \"No Failure\"\n",
        "failure_rows = df[\"Predicted Failure\"] == 1  # Select rows where failure is predicted\n",
        "\n",
        "# Select features required for failure type prediction\n",
        "failure_features = df[failure_rows].rename(columns={\n",
        "    \"Process temperature [K]\": \"Process temperature\",\n",
        "    \"Rotational speed [rpm]\": \"Rotational speed\",\n",
        "    \"Tool wear [min]\": \"Tool wear\"\n",
        "})[[\"Process temperature\", \"Rotational speed\", \"Tool wear\"]]\n",
        "\n",
        "# Predict failure type for failed cases\n",
        "if not failure_features.empty:\n",
        "    failure_predictions = model_failure_type.predict(failure_features)\n",
        "    df.loc[failure_rows, \"Predicted Failure Type\"] = failure_predictions\n",
        "    df[\"Predicted Failure Type\"] = df[\"Predicted Failure Type\"].replace(failure_type_mapping)\n",
        "\n",
        "# ✅ **Compare Predictions with Actual Labels**\n",
        "df[\"Actual Failure Type\"] = df[\"Actual Failure Type\"].replace(failure_type_reverse_mapping)  # Convert actual failure type to numbers for comparison\n",
        "df[\"Predicted Failure Type\"] = df[\"Predicted Failure Type\"].replace(failure_type_reverse_mapping)  # Convert predictions to numbers for comparison\n",
        "\n",
        "# **Evaluate Model Performance**\n",
        "failure_accuracy = accuracy_score(df[\"Actual Failure\"], df[\"Predicted Failure\"])\n",
        "failure_type_accuracy = accuracy_score(df[df[\"Actual Failure\"] == 1][\"Actual Failure Type\"], df[df[\"Actual Failure\"] == 1][\"Predicted Failure Type\"])\n",
        "\n",
        "print(\"\\n✅ **Failure Detection Accuracy:**\", round(failure_accuracy * 100, 2), \"%\")\n",
        "print(\"✅ **Failure Type Classification Accuracy:**\", round(failure_type_accuracy * 100, 2), \"%\\n\")\n",
        "\n",
        "print(\"\\n📊 **Classification Report for Failure Detection:**\\n\", classification_report(df[\"Actual Failure\"], df[\"Predicted Failure\"]))\n",
        "print(\"\\n📊 **Classification Report for Failure Type Prediction:**\\n\", classification_report(df[df[\"Actual Failure\"] == 1][\"Actual Failure Type\"], df[df[\"Actual Failure\"] == 1][\"Predicted Failure Type\"]))"
      ],
      "metadata": {
        "id": "648JLyfaweAG",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jieFemYYvixQ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}